{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "from PosterExtractor import extract_posters\n",
    "from poster_knn import PosterKNN\n",
    "from features import color_histogram_hsv, hog_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download posters of all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http exception - skipping poster of movieId: 35810\n",
      "http exception - skipping poster of movieId: 77621\n",
      "http exception - skipping poster of movieId: 121351\n",
      "http exception - skipping poster of movieId: 106605\n",
      "http exception - skipping poster of movieId: 156415\n",
      "http exception - skipping poster of movieId: 38585\n",
      "http exception - skipping poster of movieId: 23022\n",
      "http exception - skipping poster of movieId: 53571\n",
      "http exception - skipping poster of movieId: 79968\n",
      "http exception - skipping poster of movieId: 140470\n",
      "http exception - skipping poster of movieId: 242115\n",
      "http exception - skipping poster of movieId: 55602\n",
      "http exception - skipping poster of movieId: 31772\n",
      "skipped a total of 13 movies\n",
      "[35810, 77621, 121351, 106605, 156415, 38585, 23022, 53571, 79968, 140470, 242115, 55602, 31772]\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data', 'the-movies-dataset')\n",
    "movies = pd.read_csv(os.path.join(data_path, 'movies_preprocessed.csv'))\n",
    "skipped_posters = extract_posters(movies,to_folder='/Users/admin/Downloads/extracted_posters_small/')\n",
    "print('skipped a total of {} movies'.format(len(skipped_posters)))\n",
    "print(skipped_posters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Poster data into raw vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "posters_dir = '/Users/admin/Downloads/extracted_posters_small/'\n",
    "\n",
    "def image_to_raw_vector_flattened(image_url):\n",
    "    # flatten the image into a list of raw pixel intensities\n",
    "    image = io.imread(image_url)\n",
    "    img_resize = resize(image, (48,32)) # (56,37), (278,185),... keep ratio\n",
    "    return img_resize.flatten()\n",
    "\n",
    "def image_to_raw_vector(image_url):\n",
    "    image = io.imread(image_url)\n",
    "    img_resize = resize(image, (32,32,3)) # needs to be of same width/height\n",
    "    return img_resize\n",
    "\n",
    "def load_movie_posters_data(features=False):\n",
    "    images = []\n",
    "    ids = []\n",
    "    for file in os.listdir(posters_dir):\n",
    "        if features:\n",
    "            images.append(image_to_raw_vector(posters_dir+file))\n",
    "        else:\n",
    "            images.append(image_to_raw_vector_flattened(posters_dir+file))\n",
    "        ids.append(int(file.split('.')[0]))\n",
    "    return np.array(images), np.array(ids)\n",
    "\n",
    "image_data_X, image_data_y = load_movie_posters_data(features=True)\n",
    "#image_data_X_flat, image_data_y = load_movie_posters_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44598,)\n",
      "(44598,)\n"
     ]
    }
   ],
   "source": [
    "print(image_data_X.shape)\n",
    "#print(image_data_X_flat.shape)\n",
    "print(image_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from raw pixels into feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting features for 1000 / 44598 images\n",
      "Done extracting features for 2000 / 44598 images\n",
      "Done extracting features for 3000 / 44598 images\n",
      "Done extracting features for 4000 / 44598 images\n",
      "Done extracting features for 5000 / 44598 images\n",
      "Done extracting features for 6000 / 44598 images\n",
      "Done extracting features for 7000 / 44598 images\n",
      "Done extracting features for 8000 / 44598 images\n",
      "Done extracting features for 9000 / 44598 images\n",
      "Done extracting features for 10000 / 44598 images\n",
      "Done extracting features for 11000 / 44598 images\n",
      "Done extracting features for 12000 / 44598 images\n",
      "Done extracting features for 13000 / 44598 images\n",
      "Done extracting features for 14000 / 44598 images\n",
      "Done extracting features for 15000 / 44598 images\n",
      "Done extracting features for 16000 / 44598 images\n",
      "Done extracting features for 17000 / 44598 images\n",
      "Done extracting features for 18000 / 44598 images\n",
      "Done extracting features for 19000 / 44598 images\n",
      "Done extracting features for 20000 / 44598 images\n",
      "Done extracting features for 21000 / 44598 images\n",
      "Done extracting features for 22000 / 44598 images\n",
      "Done extracting features for 23000 / 44598 images\n",
      "Done extracting features for 24000 / 44598 images\n",
      "Done extracting features for 25000 / 44598 images\n",
      "Done extracting features for 26000 / 44598 images\n",
      "Done extracting features for 27000 / 44598 images\n",
      "Done extracting features for 28000 / 44598 images\n",
      "Done extracting features for 29000 / 44598 images\n",
      "Done extracting features for 30000 / 44598 images\n",
      "Done extracting features for 31000 / 44598 images\n",
      "Done extracting features for 32000 / 44598 images\n",
      "Done extracting features for 33000 / 44598 images\n",
      "Done extracting features for 34000 / 44598 images\n",
      "Done extracting features for 35000 / 44598 images\n",
      "Done extracting features for 36000 / 44598 images\n",
      "Done extracting features for 37000 / 44598 images\n",
      "Done extracting features for 38000 / 44598 images\n",
      "Done extracting features for 39000 / 44598 images\n",
      "Done extracting features for 40000 / 44598 images\n",
      "Done extracting features for 41000 / 44598 images\n",
      "Done extracting features for 42000 / 44598 images\n",
      "Done extracting features for 43000 / 44598 images\n",
      "Done extracting features for 44000 / 44598 images\n"
     ]
    }
   ],
   "source": [
    "from features import *\n",
    "\n",
    "num_color_bins = 10 # Number of bins in the color histogram\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "image_data_feats = extract_features(image_data_X, feature_fns, verbose=True)\n",
    "\n",
    "# Preprocessing: Subtract the mean feature\n",
    "mean_feat = np.mean(image_data_feats, axis=0, keepdims=True)\n",
    "image_data_feats -= mean_feat\n",
    "\n",
    "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
    "# has roughly the same scale.\n",
    "std_feat = np.std(image_data_feats, axis=0, keepdims=True)\n",
    "image_data_feats /= std_feat\n",
    "\n",
    "# Preprocessing: Add a bias dimension\n",
    "image_data_feats = np.hstack([image_data_feats, np.ones((image_data_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('image_features_X',image_data_feats)\n",
    "np.save('image_ids_y',image_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: for all 40k+ images the raw representations take 2+GB of space. For the following code only a subset of posters was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize kNN's for posters - with and without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_feats = PosterKNN()\n",
    "recommender_feats.train(image_data_feats,image_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = PosterKNN()\n",
    "recommender.train(image_data_X_flat,image_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare the k nearest neighbours of both recommenders and count the different movie ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 0, 9, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "test_ids = [32672, 862, 5833, 15602, 31357, 11862, 108]\n",
    "\n",
    "differences = []\n",
    "for id in test_ids:\n",
    "    similar1 = recommender_feats.recommend(id,k)\n",
    "    similar2 = recommender.recommend(id,k)\n",
    "    diff = list(set(similar1) - set(similar2))\n",
    "    differences.append(len(diff))\n",
    "    \n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the recommender on Toy Story (id: 862) and open the k=8 most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = recommender_feats.recommend(5833,8) # Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "for v in similar:\n",
    "    pil_im = Image.open(posters_dir+str(v)+'.jpg', 'r')\n",
    "    pil_im.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
